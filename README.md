# Web-Based RAG Agent ğŸ§ ğŸ”—

A **Web-based Retrieval-Augmented Generation (RAG) application** that allows users to paste any blog or article URL and ask questions strictly based on the provided content.

This project demonstrates an **end-to-end RAG pipeline** with web content ingestion, vector indexing, multi-turn chat, agent-based retrieval, and full observability using **LangSmith**.

---

## ğŸš€ Features

* ğŸŒ **Web Content Ingestion** â€“ Load and parse articles directly from URLs
* âœ‚ï¸ **Text Chunking** â€“ Recursive character-based splitting
* ğŸ§© **Vector Indexing** â€“ FAISS vector store with HuggingFace embeddings
* ğŸ¤– **Agent-based RAG** â€“ LangChain agent with tool-based retrieval
* ğŸ’¬ **Multi-turn Chat** â€“ Conversation memory using Streamlit session state
* ğŸ“Š **Observability** â€“ Full tracing and monitoring with LangSmith
* ğŸ–¥ï¸ **Interactive UI** â€“ Built using Streamlit

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **LangChain**
* **FAISS**
* **HuggingFace Embeddings** (`all-mpnet-base-v2`)
* **Ollama** (local LLM inference)
* **Streamlit** (web UI)
* **LangSmith** (monitoring & tracing)

---

## ğŸ“‚ Project Structure

```
web-rag-agent/
â”‚
â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ Indexing.py           # Web loading + vector store creation
â”œâ”€â”€ Agent.py              # RAG agent definition
â”œâ”€â”€ .env                  # Environment variables (not committed)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Aakash109-hub/web-rag-agent.git
cd web-rag-agent
```

### 2ï¸âƒ£ Create Virtual Environment (Optional)

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the root directory:

```env
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_PROJECT=Webbase-rag
```

Make sure **Ollama** is running locally with a supported model (e.g., `qwen3:1.7b`).

---

## â–¶ï¸ Run the Application

```bash
streamlit run app.py
```

---

## ğŸ§ª How It Works

1. User pastes a **web article URL**
2. The system:

   * Loads web content
   * Splits text into chunks
   * Creates embeddings
   * Stores them in FAISS
3. User asks questions about the article
4. The agent retrieves relevant chunks and generates answers
5. All steps are **monitored in LangSmith**

---

## ğŸ“¹ Demo Use Case

Example queries:

* *What is Google Antigravity and how can it be used?*
* *How can we set up a project in Google Antigravity?*

These questions ensure the **retriever is invoked**, not just the LLMâ€™s pre-trained knowledge.

---

## ğŸ“ˆ Observability with LangSmith

LangSmith provides visibility into:

* Agent runs
* Tool calls
* Retrieved chunks
* Token usage & latency

This helps debug and improve RAG performance.

---

## ğŸ¯ Learning Outcomes

* Understanding of RAG pipelines
* Agent-based orchestration
* Vector databases & embeddings
* Monitoring LLM systems
* Building production-style AI apps

---

## ğŸ¤ Future Improvements

* Source citations for answers
* Chunk preview in UI
* Multiple document support
* Retrieval score thresholds

---
---

â­ If you find this project useful, feel free to star the repository!
